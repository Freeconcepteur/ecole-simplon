{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est ce que le clustering ? ##\n",
    "=======================================\n",
    "\n",
    "En data-science, le clustering est une technique de regroupement d'un ensemble de données en sous-ensembles (\"clusters\") de façon à ce que les données d'un même sous-ensemble soient plus similaires entre elles qu'avec celles des autres autres sous-ensembles. C'est une technique non-supervisée car elle ne nécessite pas de données de d'entraienement avec des résultats connus.\n",
    "\n",
    "\n",
    "\n",
    "## Est ce un problème difficile ? pourquoi ? Donnez la complexité en temps et mémoire ##\n",
    "=======================================\n",
    "\n",
    "Oui, de mon point de vue, c'est un problème difficile :\n",
    "- déterminer le nombre de clusters peut être compliqué lorsque l'on ne le connait pas à l'avance. On utilise la méthode du coude ou celle de la silhouette pour le déterminer au mieux mais cela peut être couteux en temps et en calculs.\n",
    "- Optimiser le clustering (faire le tri au mieux) est très complexe => concept de problème NP-difficile\n",
    "- la dimensionalité des données : plus il y a de dimensions, plus les calculs sont importants : mémoire et temps\n",
    "\n",
    "\n",
    "\n",
    "## Quelle sont les métriques utilisés pour le clustering ? ##\n",
    "=======================================\n",
    "\n",
    "Coefficient de Silhouette, Somme des carrés intra-cluster, somme des carrés entre les clusters, indice de Davies-Bouldin, ARI, Pureté, F1-score\n",
    "\n",
    "\n",
    "\n",
    "## 3 métriques avec ground truth (dont MNI) et 3 sans ground truth (dont silhouette) ##\n",
    "=======================================\n",
    "\n",
    "### Avec ground truth (avec connaissance terrain) ###\n",
    "- ARI, Pureté, NMI (entre 0 et 1), AMI\n",
    "### Sans ground truth (avec connaissance terrain) ###\n",
    "- silhouette, WCSS, indice de Davies-Bouldin\n",
    "\n",
    "NMI et AMI sont des métriques avec ground truth (comparaison des vrais clusters aux clusters prédits). Le coéficient silhouette évalue la qualité du clustering uniquement à partir des données, sans information extérieure.\n",
    "\n",
    "\n",
    "=======================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20_newgroups #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means & TfidfVectorizer ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.30\n",
      "AMI: 0.29\n",
      "Silhouette Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score, silhouette_score\n",
    "\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes')) # pour ne récupérer qu'une partie du dataset (pour me faciliter la vie et les temps de calculs)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english') # instanciation  de l'algo de vectorisation, en supprimant les mots inutiles\n",
    "vectors = vectorizer.fit_transform(newsgroups.data) # vectorisation des données\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "num_clusters = 20 # il y a 20 newsgroups\n",
    "km = KMeans(n_clusters=num_clusters, n_init=10, random_state=42) # clsutering\n",
    "km.fit(X_train)\n",
    "\n",
    "predicted_clusters = km.predict(X_test)\n",
    "\n",
    "# Calculez les métriques\n",
    "nmi = normalized_mutual_info_score(y_test, predicted_clusters)\n",
    "ami = adjusted_mutual_info_score(y_test, predicted_clusters)\n",
    "silhouette = silhouette_score(X_test, predicted_clusters)\n",
    "\n",
    "# Affichez les résultats\n",
    "print(f\"NMI: {nmi:.2f}\")\n",
    "print(f\"AMI: {ami:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means & CountVectorizer ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.00\n",
      "AMI: 0.00\n",
      "Silhouette Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# 2ème façon\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "num_clusters = 20\n",
    "\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, n_init=10, random_state=42)\n",
    "km.fit(X_train)\n",
    "\n",
    "\n",
    "predicted_clusters = km.predict(X_test)\n",
    "\n",
    "\n",
    "nmi = normalized_mutual_info_score(y_test, predicted_clusters)\n",
    "ami = adjusted_mutual_info_score(y_test, predicted_clusters)\n",
    "silhouette = silhouette_score(X_test, predicted_clusters)\n",
    "\n",
    "print(f\"NMI: {nmi:.2f}\")\n",
    "print(f\"AMI: {ami:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constatations ##\n",
    "\n",
    "Les silhouette Score sont complètement opposés. NMI et AMI diffèrent d'une vectorisation à une autre mais ne sont jamais concluants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & TfidfVectorizer ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.04\n",
      "AMI: 0.02\n",
      "Silhouette Score: -0.21\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "num_topics = 20\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "\n",
    "document_topics = lda.transform(X_test)\n",
    "predicted_clusters = document_topics.argmax(axis=1)\n",
    "\n",
    "\n",
    "nmi = normalized_mutual_info_score(y_test, predicted_clusters)\n",
    "ami = adjusted_mutual_info_score(y_test, predicted_clusters)\n",
    "silhouette = silhouette_score(X_test, predicted_clusters)\n",
    "\n",
    "print(f\"NMI: {nmi:.2f}\")\n",
    "print(f\"AMI: {ami:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & CountVectorizer ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.32\n",
      "AMI: 0.31\n",
      "Silhouette Score: -0.22\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.01      0.04      0.02       135\n",
      "           comp.graphics       0.20      0.01      0.01       166\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00       170\n",
      "comp.sys.ibm.pc.hardware       0.04      0.01      0.01       182\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       183\n",
      "          comp.windows.x       0.01      0.01      0.01       169\n",
      "            misc.forsale       0.00      0.00      0.00       172\n",
      "               rec.autos       0.08      0.01      0.02       191\n",
      "         rec.motorcycles       0.42      0.22      0.29       198\n",
      "      rec.sport.baseball       0.02      0.01      0.02       168\n",
      "        rec.sport.hockey       0.00      0.02      0.01       163\n",
      "               sci.crypt       0.00      0.00      0.00       195\n",
      "         sci.electronics       0.08      0.01      0.02       177\n",
      "                 sci.med       0.03      0.09      0.05       172\n",
      "               sci.space       0.05      0.15      0.07       176\n",
      "  soc.religion.christian       0.00      0.00      0.00       182\n",
      "      talk.politics.guns       0.00      0.00      0.00       173\n",
      "   talk.politics.mideast       0.00      0.00      0.00       160\n",
      "      talk.politics.misc       0.03      0.01      0.01       156\n",
      "      talk.religion.misc       0.02      0.09      0.03       107\n",
      "\n",
      "                accuracy                           0.03      3395\n",
      "               macro avg       0.05      0.03      0.03      3395\n",
      "            weighted avg       0.05      0.03      0.03      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "num_topics = 20\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "\n",
    "document_topics = lda.transform(X_test)\n",
    "predicted_clusters = document_topics.argmax(axis=1)\n",
    "\n",
    "\n",
    "nmi = normalized_mutual_info_score(y_test, predicted_clusters)\n",
    "ami = adjusted_mutual_info_score(y_test, predicted_clusters)\n",
    "silhouette = silhouette_score(X_test, predicted_clusters)\n",
    "\n",
    "print(f\"NMI: {nmi:.2f}\")\n",
    "print(f\"AMI: {ami:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, predicted_clusters, target_names=newsgroups.target_names, zero_division=0)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constatations ##\n",
    "\n",
    "Aucun score n'est concluant. Je suis paumé ;-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
